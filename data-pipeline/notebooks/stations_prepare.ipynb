{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stations Preparation: Oslo Bysykkel\n",
        "\n",
        "Extracts unique stations with lat/lon and per-station summaries (trips as origin, trips as destination, total trips).\n",
        "Output: `prepared-data/stations.json`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: c:\\Users\\Nicol\\Desktop\\INF252-Course-Project\n",
            "Raw data: c:\\Users\\Nicol\\Desktop\\INF252-Course-Project\\raw-data\n",
            "Prepared data: c:\\Users\\Nicol\\Desktop\\INF252-Course-Project\\prepared-data\n",
            "No previous execution info (file does not exist yet).\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# SETUP: Project paths and execution utils\n",
        "# =============================================================================\n",
        "from pathlib import Path\n",
        "import json\n",
        "import sys\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "cwd = Path.cwd()\n",
        "project_root = cwd if (cwd / \"package.json\").exists() else cwd.parent.parent\n",
        "raw_dir = project_root / \"raw-data\"\n",
        "prepared_dir = project_root / \"prepared-data\"\n",
        "\n",
        "sys.path.insert(0, str(project_root / \"data-pipeline\"))\n",
        "from execution_utils import show_execution_banner, write_with_execution_metadata\n",
        "\n",
        "print(\"Project root:\", project_root)\n",
        "print(\"Raw data:\", raw_dir)\n",
        "print(\"Prepared data:\", prepared_dir)\n",
        "\n",
        "out_path = prepared_dir / \"stations.json\"\n",
        "_pipeline_start_time = show_execution_banner(out_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 10034294 trips\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Load trip data from raw-data/YYYY/MM.json\n",
        "# =============================================================================\n",
        "records = []\n",
        "for year_dir in sorted(raw_dir.iterdir()):\n",
        "    if not year_dir.is_dir():\n",
        "        continue\n",
        "    year = int(year_dir.name)\n",
        "    for json_path in sorted(year_dir.glob(\"*.json\")):\n",
        "        month = int(json_path.stem)\n",
        "        with open(json_path, encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "        trips = data if isinstance(data, list) else data.get(\"data\", data.get(\"trips\", []))\n",
        "        for t in trips:\n",
        "            records.append((year, month, t))\n",
        "\n",
        "rows = []\n",
        "for year, month, t in records:\n",
        "    rows.append({\n",
        "        \"year\": year,\n",
        "        \"month\": month,\n",
        "        \"start_station_id\": str(t.get(\"start_station_id\")),\n",
        "        \"start_station_name\": t.get(\"start_station_name\"),\n",
        "        \"end_station_id\": str(t.get(\"end_station_id\")),\n",
        "        \"end_station_name\": t.get(\"end_station_name\"),\n",
        "        \"start_lat\": t.get(\"start_station_latitude\"),\n",
        "        \"start_lon\": t.get(\"start_station_longitude\"),\n",
        "        \"end_lat\": t.get(\"end_station_latitude\"),\n",
        "        \"end_lon\": t.get(\"end_station_longitude\"),\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df = df.dropna(subset=[\"start_lat\", \"start_lon\", \"end_lat\", \"end_lon\"])\n",
        "\n",
        "print(f\"Loaded {len(df)} trips\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build Station Catalog with Summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stations: 292\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Build station catalog: id, name, lat, lon, trips_as_origin, trips_as_dest, total_trips\n",
        "# =============================================================================\n",
        "stations_start = df.groupby(\"start_station_id\").agg({\n",
        "    \"start_station_name\": \"first\",\n",
        "    \"start_lat\": \"first\",\n",
        "    \"start_lon\": \"first\",\n",
        "}).rename(columns={\"start_station_name\": \"name\", \"start_lat\": \"lat\", \"start_lon\": \"lon\"})\n",
        "stations_start[\"trips_as_origin\"] = df.groupby(\"start_station_id\").size()\n",
        "\n",
        "stations_end = df.groupby(\"end_station_id\").agg({\n",
        "    \"end_station_name\": \"first\",\n",
        "    \"end_lat\": \"first\",\n",
        "    \"end_lon\": \"first\",\n",
        "}).rename(columns={\"end_station_name\": \"name\", \"end_lat\": \"lat\", \"end_lon\": \"lon\"})\n",
        "stations_end[\"trips_as_dest\"] = df.groupby(\"end_station_id\").size()\n",
        "\n",
        "all_ids = set(stations_start.index) | set(stations_end.index)\n",
        "stations = []\n",
        "for sid in sorted(all_ids, key=lambda x: (len(str(x)), x)):\n",
        "    trips_origin = int(stations_start.loc[sid][\"trips_as_origin\"]) if sid in stations_start.index else 0\n",
        "    trips_dest = int(stations_end.loc[sid][\"trips_as_dest\"]) if sid in stations_end.index else 0\n",
        "    if sid in stations_start.index:\n",
        "        row = stations_start.loc[sid]\n",
        "    else:\n",
        "        row = stations_end.loc[sid]\n",
        "    stations.append({\n",
        "        \"id\": sid,\n",
        "        \"name\": str(row[\"name\"]),\n",
        "        \"lat\": float(row[\"lat\"]),\n",
        "        \"lon\": float(row[\"lon\"]),\n",
        "        \"trips_as_origin\": trips_origin,\n",
        "        \"trips_as_dest\": trips_dest,\n",
        "        \"total_trips\": trips_origin + trips_dest,\n",
        "    })\n",
        "\n",
        "print(f\"Stations: {len(stations)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote c:\\Users\\Nicol\\Desktop\\INF252-Course-Project\\prepared-data\\stations.json\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Write output\n",
        "# =============================================================================\n",
        "write_with_execution_metadata(out_path, {\"stations\": stations}, _pipeline_start_time)\n",
        "print(f\"Wrote {out_path}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "inf252-data-pipeline",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
